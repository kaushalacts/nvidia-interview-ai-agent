version: "3.9"

networks:
  app_net:

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - app_net
    deploy:
      resources:
        limits:
          memory: 6g
          cpus: "2"

  backend:
    image: thehiddenboy143/nvidia-interview-backend:1.0.3
    container_name: interview-backend
    volumes:
      - backend_sqlite:/data
      - chroma_data:/app/rag/chroma_db
    environment:
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: mistral
    depends_on:
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8000/health"]
      interval: 30s
      retries: 5
    restart: unless-stopped
    networks:
      - app_net
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1"

  ui:
    image: thehiddenboy143/nvidia-interview-ui:1.0.1
    container_name: interview-ui
    ports:
      - "8501:8501"
    environment:
      API: http://backend:8000
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - app_net

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    volumes:
      - n8n_data:/home/node/.n8n
    restart: unless-stopped
    networks:
      - app_net

volumes:
  backend_sqlite:
  chroma_data:
  ollama_data:
  n8n_data:
